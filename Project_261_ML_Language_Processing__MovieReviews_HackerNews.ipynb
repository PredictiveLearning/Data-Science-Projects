{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: ML - Language Processing (Movie Reviews and Hacker News)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Questions to address:\n",
    "- Predict the tone of movie reviews from text\n",
    "- Predict number of upvotes from HackerNews headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Tools:\n",
    "- Naive Bayes for Sentiment Analysis\n",
    "- Models: \n",
    "  - Naive Bayes for Sentiment Analysis\n",
    "  - Bag of words model + LinearRegression and RandomForestRegressor\n",
    "- Error Metric: accuracy_score + AUCROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### load defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaults Loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import requests \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Math\n",
    "\n",
    "from functions import *\n",
    "\n",
    "plt.rcParams.update({'axes.titlepad': 20, 'font.size': 12, 'axes.titlesize':20})\n",
    "\n",
    "colors = [(0/255,107/255,164/255), (255/255, 128/255, 14/255), 'red', 'green', '#9E80BA', '#8EDB8E', '#58517A']\n",
    "Ncolors = 10\n",
    "color_map = plt.cm.Blues_r(np.linspace(0.2, 0.5, Ncolors))\n",
    "#color_map = plt.cm.tab20c_r(np.linspace(0.2, 0.5, Ncolors))\n",
    "\n",
    "\n",
    "#specific to this project\n",
    "import csv\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "print(\"Defaults Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Naive Bayes for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### dataset: file containing movie reviews\n",
    "- each file contains a 'tone' label (-1 for negative review, 1 for positive review) that we want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the training data\n",
    "with open(\"./data/text_train.csv\", 'r') as file:\n",
    "    reviews = list(csv.reader(file))\n",
    "    \n",
    "with open(\"./data/text_test.csv\", 'r') as file:\n",
    "    test = list(csv.reader(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.635\n",
      "AUC of the predictions: 0.636\n"
     ]
    }
   ],
   "source": [
    "# Generate counts from text using a vectorizer  \n",
    "# We can choose from other available vectorizers, and set many different options\n",
    "\n",
    "# This code performs our step of computing word counts\n",
    "vectorizer = CountVectorizer(stop_words='english', max_df=.05)\n",
    "train_features = vectorizer.fit_transform([r[0] for r in reviews])\n",
    "test_features = vectorizer.transform([r[0] for r in test])\n",
    "test_target = [int(r[1]) for r in test]\n",
    "\n",
    "# Fit a Naive Bayes model to the training data\n",
    "# train the model using the word counts we computed and the existing classifications in the training set\n",
    "nb = MultinomialNB()\n",
    "nb.fit(train_features, [int(r[1]) for r in reviews])\n",
    "\n",
    "# Now we can use the model to predict classifications for our test features\n",
    "predictions = nb.predict(test_features)\n",
    "\n",
    "# Compute the error\n",
    "accuracy = metrics.accuracy_score(predictions, test_target)\n",
    "\n",
    "print(\"Accuracy: {:0.3f}\".format(accuracy))\n",
    "\n",
    "# Generate the ROC curve using scikits-learn\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_target, predictions, pos_label=1)\n",
    "\n",
    "# Measure the area under the curve\n",
    "# The closer to 1 it is, the \"better\" the predictions\n",
    "print(f\"AUC of the predictions: {metrics.auc(fpr, tpr):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Dataset: HackerNews posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_time</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-17T16:57:59Z</td>\n",
       "      <td>1</td>\n",
       "      <td>blog.jonasbandi.net</td>\n",
       "      <td>Software: Sadly we did adopt from the construc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-02-04T02:36:30Z</td>\n",
       "      <td>1</td>\n",
       "      <td>blogs.wsj.com</td>\n",
       "      <td>Google’s Stock Split Means More Control for L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-10-26T07:11:29Z</td>\n",
       "      <td>1</td>\n",
       "      <td>threatpost.com</td>\n",
       "      <td>SSL DOS attack tool released exploiting negoti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-04-03T15:43:44Z</td>\n",
       "      <td>67</td>\n",
       "      <td>algorithm.com.au</td>\n",
       "      <td>Immutability and Blocks Lambdas and Closures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-13T16:49:20Z</td>\n",
       "      <td>1</td>\n",
       "      <td>winmacsofts.com</td>\n",
       "      <td>Comment optimiser la vitesse de Wordpress?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        submission_time  upvotes                  url  \\\n",
       "0  2010-02-17T16:57:59Z        1  blog.jonasbandi.net   \n",
       "1  2014-02-04T02:36:30Z        1        blogs.wsj.com   \n",
       "2  2011-10-26T07:11:29Z        1       threatpost.com   \n",
       "3  2011-04-03T15:43:44Z       67     algorithm.com.au   \n",
       "4  2013-01-13T16:49:20Z        1      winmacsofts.com   \n",
       "\n",
       "                                            headline  \n",
       "0  Software: Sadly we did adopt from the construc...  \n",
       "1   Google’s Stock Split Means More Control for L...  \n",
       "2  SSL DOS attack tool released exploiting negoti...  \n",
       "3       Immutability and Blocks Lambdas and Closures  \n",
       "4         Comment optimiser la vitesse de Wordpress?  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "submissions = pd.read_csv(\"./data/sel_hn_stories.csv\")\n",
    "submissions.columns = [\"submission_time\", \"upvotes\", \"url\", \"headline\"]\n",
    "submissions = submissions.dropna()\n",
    "\n",
    "display(submissions[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create list of cleaned individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['software', 'sadly', 'we', 'did', 'adopt', 'from', 'the', 'construction', 'analogy'], ['googles', 'stock', 'split', 'means', 'more', 'control', 'for', 'larry', 'and', 'sergey'], ['ssl', 'dos', 'attack', 'tool', 'released', 'exploiting', 'negotiation', 'overhead']]\n"
     ]
    }
   ],
   "source": [
    "tokenized_headlines = []\n",
    "\n",
    "headlines = submissions['headline']\n",
    "\n",
    "for element in headlines:    \n",
    "    tokenized_headlines.append(element.split())\n",
    "    \n",
    "punctuation = [\",\", \":\", \";\", \".\", \"'\", '\"', \"’\", \"?\", \"/\", \"-\", \"+\", \"&\", \"(\", \")\"]\n",
    "clean_tokenized = []\n",
    "\n",
    "for element in tokenized_headlines:\n",
    "    clean_token = []\n",
    "    for token in element:\n",
    "        for punc in punctuation:\n",
    "            token = token.replace(punc,\"\")\n",
    "        clean_token.append(token.lower())\n",
    "        \n",
    "    clean_tokenized.append(clean_token)\n",
    "    \n",
    "print(clean_tokenized[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "counts tokens that appear two times or more and create dataframe with bag of words initiated with 0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>as</th>\n",
       "      <th>you</th>\n",
       "      <th>is</th>\n",
       "      <th>the</th>\n",
       "      <th>split</th>\n",
       "      <th>good</th>\n",
       "      <th>how</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  for  as  you  is  the  split  good  how\n",
       "0    0    0   0    0   0    0      0     0    0\n",
       "1    0    0   0    0   0    0      0     0    0\n",
       "2    0    0   0    0   0    0      0     0    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "unique_tokens = []\n",
    "single_tokens = []\n",
    "\n",
    "for element in clean_tokenized:\n",
    "    for item in element:    \n",
    "        #single tokens don't add much\n",
    "        if(item not in single_tokens):\n",
    "            single_tokens.append(item)\n",
    "        #only had to unique tokens if it appears a second time\n",
    "        else:\n",
    "            if(item not in unique_tokens):\n",
    "                unique_tokens.append(item)\n",
    "  \n",
    "counts = pd.DataFrame(0, index = np.arange(len(clean_tokenized)), columns = unique_tokens)\n",
    "\n",
    "display(counts.iloc[:3,:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create bag of words model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>as</th>\n",
       "      <th>you</th>\n",
       "      <th>good</th>\n",
       "      <th>what</th>\n",
       "      <th>de</th>\n",
       "      <th>amazon</th>\n",
       "      <th>cloud</th>\n",
       "      <th>at</th>\n",
       "      <th>google</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   as  you  good  what  de  amazon  cloud  at  google\n",
       "0   0    0     0     0   0       0      0   0       0\n",
       "1   0    0     0     0   0       0      0   0       0\n",
       "2   0    0     0     0   0       0      0   0       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx, element in enumerate(clean_tokenized):\n",
    "    for item in element:\n",
    "        if(item in unique_tokens):\n",
    "            counts.iloc[idx][item]+=1\n",
    "            \n",
    "#remove words that appear less than 5 or more than 100 times            \n",
    "word_counts = counts.sum(axis=0)    \n",
    "counts = counts.loc[:,(word_counts>=5) & (word_counts<=100)]\n",
    "\n",
    "display(counts.iloc[:3,:9])         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**split into train and test, train and predict and calculate error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE LinearRegression: 51.489\n",
      "RMSE RandomForest: 47.219\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, submissions[\"upvotes\"], test_size=0.2, random_state=1)\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "mse = ((y_test-predictions)**2).sum()/len(y_test)\n",
    "print(\"RMSE LinearRegression: {:0.3f}\".format(np.sqrt(mse)))\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=150, random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "mse = ((y_test-predictions)**2).sum()/len(y_test)\n",
    "print(\"RMSE RandomForest: {:0.3f}\".format(np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
